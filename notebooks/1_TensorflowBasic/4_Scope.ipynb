{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scope\n",
    "---\n",
    "In this notebook, I'll describe\n",
    "- name_scope\n",
    "- variable_scope\n",
    "\n",
    "## [tf.name_scope](https://www.tensorflow.org/api_docs/python/tf/name_scope)\n",
    "The `tf.name_scope` defines the group of some variables in a graph.  \n",
    "It add a prefix to the operation or variable made by using `tf.Variable`.  \n",
    "__Note that the `tf.name_scope` is ignore by `tf.get_variable`.__  \n",
    "Some google developer recommends that we should use variable_scope and not use name_scope because of the reason above.\n",
    "\n",
    "## [tf.variable_scope](https://www.tensorflow.org/api_docs/python/tf/variable_scope)\n",
    "> A context manager for defining ops that creates variables (layers).\n",
    "This context manager validates that the (optional) values are from the same graph, ensures that graph is the default graph, and pushes a name scope and a variable scope.\n",
    "If name_or_scope is not None, it is used as is. If name_or_scope is None, then default_name is used. In that case, if the same name has been previously used in the same scope, it will be made unique by appending _N to it.\n",
    "\n",
    "## tf.name_scope vs. tf.variable_scope\n",
    "The concepts of both scope are the same. They define the prefix of the operation or variable. Both scopes have the same effect on all operations as well as variables created using tf.Variable, i.e., the scope will be added as a prefix to the operation or variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  1.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"tensorflow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "### - `tf.name_scope` / `tf.variable_scope`\n",
    "`tf.get_variable` ignores the scope defined by `tf.name_scope()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name_scope/var1:0\n",
      "var2:0\n",
      "name_scope/Add:0\n"
     ]
    }
   ],
   "source": [
    "# clear graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"name_scope\"):\n",
    "    # tf.Variable()\n",
    "    v1 = tf.Variable([1,2,3], name=\"var1\", dtype=tf.float32)\n",
    "    # tf.get_variable()\n",
    "    v2 = tf.get_variable(\"var2\", shape=[3,], dtype=tf.float32)\n",
    "    # define ops\n",
    "    add = tf.add(v1, v2)\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)\n",
    "print(add.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.get_variable` doesn't ignore the scope defined by `tf.variable_scope`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_scope/var1:0\n",
      "variable_scope/var2:0\n",
      "variable_scope/Add:0\n"
     ]
    }
   ],
   "source": [
    "# clear graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"variable_scope\"):\n",
    "    # tf.Variable()\n",
    "    v1 = tf.Variable([1,2,3], name=\"var1\", dtype=tf.float32)\n",
    "    # tf.get_variable()\n",
    "    v2 = tf.get_variable(\"var2\", shape=[3,], dtype=tf.float32)\n",
    "    # define ops\n",
    "    add = tf.add(v1, v2)\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)\n",
    "print(add.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplication of the variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_scope/var1:0\n",
      "variable_scope/var2:0\n",
      "variable_scope/Add:0\n",
      "\n",
      "\n",
      "variable_scope_1/var1:0\n",
      "variable_scope/var3:0\n",
      "variable_scope_1/Add:0\n"
     ]
    }
   ],
   "source": [
    "# clear graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope(\"variable_scope\"):\n",
    "    v1 = tf.Variable([1,2,3], name=\"var1\", dtype=tf.float32)\n",
    "    v2 = tf.get_variable(\"var2\", shape=[3,], dtype=tf.float32)\n",
    "    add = tf.add(v1, v2)\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)\n",
    "print(add.name)\n",
    "print(\"\\n\")\n",
    "\n",
    "with tf.variable_scope(\"variable_scope\"):\n",
    "    # The scope name will be variable_scope_1 because variable_scope/v1 is already exists.\n",
    "    v1 = tf.Variable([1,2,3], name=\"var1\", dtype=tf.float32)\n",
    "    # The var3 will be added to \"variable_scope\".\n",
    "    v3 = tf.get_variable(\"var3\", shape=[3,], dtype=tf.float32)\n",
    "    # The scope name will be variable_scope_1 because variable_scope/add is already exists.\n",
    "    add = tf.add(v1, v3)\n",
    "    \n",
    "print(v1.name)\n",
    "print(v3.name)\n",
    "print(add.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Sharing variables](https://www.tensorflow.org/guide/variables)\n",
    "Example: Sharing variable `w` in the calculation bellow.\n",
    "- output1 = input_A $\\cdot$ w\n",
    "- output2 = input_B $\\cdot$ w\n",
    "- final_output = output1 + output2\n",
    "\n",
    "Failure Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable matmul/weight already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\yoshiyuki\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\yoshiyuki\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\yoshiyuki\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e3b22a97b8ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0moutput1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0moutput2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_B\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# This will be error because m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e3b22a97b8ae>\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(input_vector)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"matmul\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"weight\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1485\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1487\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1235\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1237\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    538\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    859\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 861\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    862\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable matmul/weight already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\yoshiyuki\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\Users\\yoshiyuki\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\yoshiyuki\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# clear graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_A = tf.placeholder(tf.float32, shape=[3,1], name=\"input_A\")\n",
    "input_B = tf.placeholder(tf.float32, shape=[3,1], name=\"input_B\")\n",
    "\n",
    "# define ops\n",
    "def matmul(input_vector):\n",
    "    with tf.variable_scope(\"matmul\"):\n",
    "        w = tf.get_variable(\"weight\", shape=(1,3), initializer=tf.initializers.ones)\n",
    "        return tf.matmul(input_vector, w)\n",
    "\n",
    "output1 = matmul(input_A)\n",
    "output2 = matmul(input_B) # This will be error because matmul/weight already exists.\n",
    "final_output = tf.add(output1, output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul/weight:0\n",
      "matmul/weight:0\n"
     ]
    }
   ],
   "source": [
    "# clear graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_A = tf.placeholder(tf.float32, shape=[3,1], name=\"input_A\")\n",
    "input_B = tf.placeholder(tf.float32, shape=[3,1], name=\"input_B\")\n",
    "\n",
    "# define ops\n",
    "def matmul(input_vector, reuse = False):\n",
    "    with tf.variable_scope(\"matmul\", reuse=reuse):\n",
    "        w = tf.get_variable(\"weight\", shape=(1,3), initializer=tf.initializers.ones)\n",
    "        print(w.name)\n",
    "        return tf.matmul(input_vector, w)\n",
    "\n",
    "output1 = matmul(input_A)\n",
    "output2 = matmul(input_B, reuse = True) # This will be error because matmul/weight already exists.\n",
    "final_output = tf.add(output1, output2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
